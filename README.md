# Сервис автоматической суммаризации новостных текстов

Проект по созданию DL-модели и сервиса для генерации коротких, осмысленных выжимок (саммари) из длинных новостных статей на русском языке.

## Цель проекта

Основная цель — **повысить продуктивность работы с информацией**, предоставляя пользователям сервис для быстрого получения сути из больших текстов. Это позволяет экономить время аналитиков, редакторов и менеджеров, ускоряя принятие решений и мониторинг информационного поля.

## Набор данных

Для создания и всесторонней оценки модели будут использоваться несколько публичных датасетов, что позволит проверить её устойчивость и способность к обобщению.

1.  **[Gazeta](https://huggingface.co/datasets/IlyaGusev/gazeta)**
    - **Описание:** Содержит ~60,000 пар "статья-саммари" с российских новостных сайтов. Будет использоваться как основной источник данных для обучения (fine-tuning) модели.

2.  **[MLSUM](https://huggingface.co/datasets/reciTAL/mlsum)**
    - **Описание:** Большой многоязычный датасет для суммаризации. (Будет использоваться для экспериментов с дообучением русскоязычная часть)
   
3.  **[РИА Новости](https://www.kaggle.com/datasets/yutkin/corpus-of-russian-news-articles-from-lenta)**
    - **Описание:** Корпус новостных статей от агентства "РИА Новости".
    Будет использоваться как **независимый тестовый набор**. Модель, обученная на `Gazeta` и `MLSUM`, будет оцениваться на этих данных, чтобы проверить её способность работать с текстами другого стиля и источника.

## План экспериментов

1.  **Исследовательский анализ данных (EDA):**
    - Проанализировать распределение длин исходных текстов и саммари. (для дальнейшей настройки обучения)
    - Построить облака слов для текстов и саммари, чтобы понять основные темы. 
    - Проверить данные на наличие шумов, пустых строк и аномалий.

2.  **Выбор Baseline-модели:**
    - Реализовать простой  метод, например, `TextRank` или `LexRank`. Это даст baseline, с которым будет сравниваться DL-модель.

3.  **Выбор и подготовка основной DL-модели:**
    - В качестве основной модели будет использоваться предобученная seq2seq. Основной кандидат — **`google/mt5-small`**.

4.  **Обучение (Fine-tuning):**
    - Написать скрипт для fine-tuning'а модели
    - В качестве основной метрики для валидации в процессе обучения использовать **ROUGE Score**.

5.  **Оценка:**
    - Оценить финальную модель на отложенной тестовой выборке по метрикам `ROUGE-1`, `ROUGE-2` и `ROUGE-L`.
    - Провести качественный анализ: вручную прочитать 50-100 сгенерированных саммари и сравнить их с эталонными. Оценить связность, точность и отсутствие "галлюцинаций".
    - Попробовать разные стратегии декодирования (beam search, top-k sampling) для улучшения качества генерации.


## Целевые метрики 

- Среднее время ответа модели: ≤ 3 секунды на статью до 1000 слов.
- Доля неуспешных запросов: ≤ 1 %.

Использование ресурсов (SLA):

- GPU-память (VRAM): < 8 ГБ на инстанс.
- RAM: < 16 ГБ на инстанс.

Качество модели (ключевая метрика для суммаризации):

- ROUGE-L: ≥ 0.3
- Качественная оценка: Доля сгенерированных саммари, которые являются связными и не содержат "галлюцинаций", должна быть ≥ 90% по результатам ручной проверки на 100 примерах.


## Запуск обучения
`pip install -r requirements.txt`

Собираем конфиг обучения пример в configs/train_config.yaml
Запуск обучения 

`python src/train.py configs/train_config.yaml`

Результаты в папке с результатами из конфига 

Запуск валидации

С базовой моделью (без дообучения)

`python run_evaluation.py --config_path ../configs/train_config.yaml`

С дообученной моделью

`python run_evaluation.py --config_path ../configs/train_config.yaml --model_path $PATH_TO_CKPT`

На выходе метрики и примеры генераций
